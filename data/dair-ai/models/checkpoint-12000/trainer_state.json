{
  "best_metric": 0.34824275970458984,
  "best_model_checkpoint": "./data/dair-ai/models/checkpoint-12000",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12,
      "grad_norm": 16.32712745666504,
      "learning_rate": 1.95e-05,
      "loss": 0.5581,
      "step": 500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.46766579151153564,
      "learning_rate": 1.9e-05,
      "loss": 0.5647,
      "step": 1000
    },
    {
      "epoch": 0.38,
      "grad_norm": 31.287105560302734,
      "learning_rate": 1.8500000000000002e-05,
      "loss": 0.5652,
      "step": 1500
    },
    {
      "epoch": 0.5,
      "grad_norm": 20.051237106323242,
      "learning_rate": 1.8e-05,
      "loss": 0.5579,
      "step": 2000
    },
    {
      "epoch": 0.62,
      "grad_norm": 13.112052917480469,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.5086,
      "step": 2500
    },
    {
      "epoch": 0.75,
      "grad_norm": 46.16505432128906,
      "learning_rate": 1.7e-05,
      "loss": 0.4989,
      "step": 3000
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.929090976715088,
      "learning_rate": 1.65e-05,
      "loss": 0.5326,
      "step": 3500
    },
    {
      "epoch": 1.0,
      "grad_norm": 44.384864807128906,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.5156,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.896,
      "eval_loss": 0.39583274722099304,
      "eval_runtime": 23.7432,
      "eval_samples_per_second": 84.235,
      "eval_steps_per_second": 21.059,
      "step": 4000
    },
    {
      "epoch": 1.12,
      "grad_norm": 74.74516296386719,
      "learning_rate": 1.55e-05,
      "loss": 0.4865,
      "step": 4500
    },
    {
      "epoch": 1.25,
      "grad_norm": 74.1645278930664,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.4833,
      "step": 5000
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.0258634090423584,
      "learning_rate": 1.45e-05,
      "loss": 0.4682,
      "step": 5500
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.031134994700551033,
      "learning_rate": 1.4e-05,
      "loss": 0.4516,
      "step": 6000
    },
    {
      "epoch": 1.62,
      "grad_norm": 73.88902282714844,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.3988,
      "step": 6500
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.721259593963623,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.4833,
      "step": 7000
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.8943026065826416,
      "learning_rate": 1.25e-05,
      "loss": 0.4896,
      "step": 7500
    },
    {
      "epoch": 2.0,
      "grad_norm": 40.471431732177734,
      "learning_rate": 1.2e-05,
      "loss": 0.4501,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.911,
      "eval_loss": 0.3676304817199707,
      "eval_runtime": 25.3742,
      "eval_samples_per_second": 78.82,
      "eval_steps_per_second": 19.705,
      "step": 8000
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5487248301506042,
      "learning_rate": 1.15e-05,
      "loss": 0.4704,
      "step": 8500
    },
    {
      "epoch": 2.25,
      "grad_norm": 60.23822784423828,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.4367,
      "step": 9000
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.0482157468795776,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.3856,
      "step": 9500
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.05179046466946602,
      "learning_rate": 1e-05,
      "loss": 0.4565,
      "step": 10000
    },
    {
      "epoch": 2.62,
      "grad_norm": 13.404703140258789,
      "learning_rate": 9.5e-06,
      "loss": 0.3607,
      "step": 10500
    },
    {
      "epoch": 2.75,
      "grad_norm": 61.7602424621582,
      "learning_rate": 9e-06,
      "loss": 0.4784,
      "step": 11000
    },
    {
      "epoch": 2.88,
      "grad_norm": 51.44121551513672,
      "learning_rate": 8.5e-06,
      "loss": 0.4354,
      "step": 11500
    },
    {
      "epoch": 3.0,
      "grad_norm": 19.99077606201172,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.417,
      "step": 12000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9145,
      "eval_loss": 0.34824275970458984,
      "eval_runtime": 24.5637,
      "eval_samples_per_second": 81.421,
      "eval_steps_per_second": 20.355,
      "step": 12000
    }
  ],
  "logging_steps": 500,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 6330991256174592.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
